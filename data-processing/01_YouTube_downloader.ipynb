{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribing YouTube Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Overview\n",
    "\n",
    "1. Downloading YouTube videos and converting to MP3 format using yt-dlp\n",
    "2. Setting up Gradio as a server on a remote GPU computer to run Whisper AI\n",
    "3. Using Gradio client to send audio data to the remote server for processing\n",
    "4. Processing the audio files with Whisper AI for transcription\n",
    "5. Retrieving and storing the transcripts with checkpointing for reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install moviepy\n",
    "%pip install -U openai-whisper\n",
    "%pip install -U yt-dlp\n",
    "%pip install gradio_client\n",
    "%pip install gradio\n",
    "%pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing\n",
    "from moviepy import *\n",
    "import json\n",
    "from os import listdir, path\n",
    "import yt_dlp\n",
    "from gradio_client import Client\n",
    "from gradio_client.utils import handle_file\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your notebook to the right directrory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"/Users/DIRECTORY/PATH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON file into a pandas DataFrame\n",
    "JSON_PATH = \"data/dataset_youtube_vids.json\"\n",
    "with open(JSON_PATH, \"r\") as file: \n",
    "    df = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 01 <br>\n",
    "TODO: Loop throug the dataset <br>\n",
    "TODO: add a new column index starting 0 for each row <br>\n",
    "\n",
    "Step 02 <br>\n",
    "TODO: Loop through the dataset <br>\n",
    "TODO: Get URL for each video <br>\n",
    "TODO: Get index <br>\n",
    "TODO: name the audio {index}-video<br>\n",
    "TODO: Download audios\n",
    "\n",
    "Step 03<br>\n",
    "TODO: Transicribe with Whisper AI on different computer with GPU <br>\n",
    "TODO: ON SERVER -> Function to receive an audio file and transcribe with Whisper<br>\n",
    "TODO: ON SERVER -> get Gradio Interface API for the local client<br>\n",
    "TODO: LOCAL: Run the client <br>\n",
    "TODO: LOCAL: Load files \n",
    "TODO: LOCAL: Loop throug files and send to Gradio <br>\n",
    "TODO: Append the transcript to a new column caled transcribed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 01\n",
    "# TODO: Loop throug the dataset \n",
    "# TODO: add a new column index starting 0 for each row \n",
    "for  idx, row in enumerate(df):\n",
    "    row[\"index\"] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downlaod YouTube and convert to Audio\n",
    "Using ydl_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Loop through the dataset \n",
    "for row in df:\n",
    "    # TODO: Get URL for each video\n",
    "    print(row[\"url\"])\n",
    "    url = row[\"url\"]\n",
    "    # TODO: Get index \n",
    "    print(row[\"index\"])\n",
    "    id = row[\"index\"]\n",
    "    # TODO: name the audio index-video\n",
    "    ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'mp3',\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "    'outtmpl': f'audio_files/{id}-audio.%(ext)s'\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking pkl file for interrupted sessions\n",
    "The computers are not very fast and we have 1014 audios to transcribe the transcription process is done through multiple days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the latest checkpoint\n",
    "with open('export_transcribed_data.pkl', 'rb') as f:\n",
    "    df_copy = pickle.load(f)\n",
    "transcribed_count = sum(1 for item in df_copy if 'transcript' in item and item['transcript'])\n",
    "print(f\"Loaded checkpoint with {transcribed_count} transcribed files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using gradio_client hosted on different computer to use GPU to run Whisper AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clients\n",
    "# 1 \n",
    "client = Client(\"https://b95cbd9371e8e6844b.gradio.live/\")     \n",
    "#2\n",
    "client = Client(\"https://b15ac7efb347bf7f1a.gradio.live/\")     \n",
    "#3\n",
    "client = Client(\"https://debe7dedf66c60de09.gradio.live/\")     \n",
    "#4\n",
    "client = Client(\"https://c571097d3ed33d1fb0.gradio.live/\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_folder = \"audio_files/\"\n",
    "audio_files = [f for f in listdir(audio_folder) if f.endswith(\".mp3\")]\n",
    "\n",
    "# Track progress - now using the full length\n",
    "total_files = len(audio_files)\n",
    "processed = 0\n",
    "skipped = 0\n",
    "\n",
    "# Loop through ALL audio files (removed the [:100] slice)\n",
    "for fname in audio_files:\n",
    "    file_path = path.join(audio_folder, fname)\n",
    "    number = int(fname.split(\"-\")[0])\n",
    "    \n",
    "    # Find matching item in df_copy\n",
    "    matching_item = next((item for item in df_copy if item[\"index\"] == number), None)\n",
    "    \n",
    "    # Skip if already transcribed\n",
    "    if matching_item and \"transcript\" in matching_item and matching_item[\"transcript\"]:\n",
    "        print(f\"Skipping {fname} - already transcribed\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "        \n",
    "    if matching_item:\n",
    "        print(f\"Processing {fname} ({processed+1}/{total_files})\")\n",
    "        try:\n",
    "            result = client.predict(\n",
    "                audio=handle_file(file_path),\n",
    "                api_name=\"/predict\"\n",
    "            )\n",
    "            matching_item[\"transcript\"] = result\n",
    "            print(f\"Transcribed: {result[:100]}...\")  # Print start of transcript\n",
    "            \n",
    "            # Save checkpoint every 10 files (or adjust as needed for larger datasets)\n",
    "            processed += 1\n",
    "            if processed % 10 == 0:\n",
    "                with open('transcribed_data.pkl', 'wb') as f:\n",
    "                    pickle.dump(df_copy, f)\n",
    "                print(f\"Checkpoint saved ({processed}/{total_files})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {fname}: {e}\")\n",
    "            # Save on error to prevent losing progress\n",
    "            with open('transcribed_data_error.pkl', 'wb') as f:\n",
    "                pickle.dump(df_copy, f)\n",
    "            print(\"Progress saved after error\")\n",
    "    else:\n",
    "        print(f\"No matching index found for {fname}\")\n",
    "\n",
    "print(f\"Finished processing. Transcribed: {processed}, Skipped: {skipped}\")\n",
    "\n",
    "# Save final results\n",
    "with open('transcribed_data.pkl', 'wb') as f:\n",
    "    pickle.dump(df_copy, f)\n",
    "\n",
    "with open('transcribed_data.json', 'w') as f:\n",
    "    json.dump(df_copy, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the check ponits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double checking just in case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('export_transcribed_data.pkl', 'wb') as f:\n",
    "    pickle.dump(df_copy, f)\n",
    "    \n",
    "with open('export_transcribed_data.json', 'w') as f:\n",
    "    json.dump(df_copy, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyenv 3.10)",
   "language": "python",
   "name": "pyenv310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
